# Training configuration
total_timesteps: 500_000
n_envs: 8
max_episode_steps: 500
n_steps: 64
batch_size: ${eval:'${n_steps} * ${n_envs}'}
learning_rate: 0.0003
n_epochs: 15

# All network and policy configuration
policy_type: MlpPolicy
policy_kwargs:
  net_arch: [256, 128, 64]

wandb:
  enabled: true

# Hydra output directory configuration
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S} 
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}


