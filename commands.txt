python train.py --multirun \
  n_steps=64,128,256,512,1024 \
  batch_size=512,1024,2048,4096,8192 \
  n_epochs=3,5,10,15 \
  policy_kwargs.net_arch=[64,64],[128,128],[256,256],[512,512],[64,64,64],[128,128,128],[256,128,64] 

  

python train.py --multirun \
  hydra/launcher=ray \
  +hydra.launcher.ray.init.num_cpus=64 \
  +hydra.launcher.ray.init.num_gpus=2 \
  +hydra.launcher.ray.remote.num_cpus=8 \
  +hydra.launcher.ray.remote.num_gpus=0.25 \
  n_steps=32\
  n_epochs=10,15 \
  policy_kwargs.net_arch=[256,256],[512,512],[64,64,64],[128,128,128],[256,128,64] \
  n_stack=3,5,8